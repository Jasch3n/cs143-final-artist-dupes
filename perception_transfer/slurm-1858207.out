## SLURM PROLOG ###############################################################
##    Job ID : 1858207
##  Job Name : batch.sh
##  Nodelist : gpu2105
##      CPUs : 1
##   Mem/CPU : 51200 MB
## Directory : /oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer
##   Job Started : Wed May  1 02:50:19 AM EDT 2024
###############################################################################

    Copy/Paste this in your local terminal to ssh tunnel with remote
    -----------------------------------------------------------------
    ssh -N -L 8708:172.20.217.5:8708 syu66@ssh.ccv.brown.edu
    -----------------------------------------------------------------
    Then open a browser on your local machine to the following address
    ------------------------------------------------------------------
    localhost:8708  (prefix w/ https:// if using password)
    ------------------------------------------------------------------
    
Wed May  1 02:50:19 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:E1:00.0 Off |                  N/A |
| 30%   23C    P8              28W / 350W |     13MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     55867      G   /usr/libexec/Xorg                             5MiB |
+---------------------------------------------------------------------------------------+
  0%|          | 0/4319 [00:00<?, ?it/s]100%|██████████| 4319/4319 [00:00<00:00, 6255248.27it/s]
Traceback (most recent call last):
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py", line 16, in <module>
    model = ImageTransformer()
            ^^^^^^^^^^^^^^^^^^
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/image_transform_net.py", line 10, in __init__
    nn.Conv2d(
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 447, in __init__
    super().__init__(
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 134, in __init__
    self.weight = Parameter(torch.empty(
                            ^^^^^^^^^^^^
TypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:
 * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
 * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

