## SLURM PROLOG ###############################################################
##    Job ID : 1860701
##  Job Name : batch.sh
##  Nodelist : gpu2109
##      CPUs : 1
##   Mem/CPU : 51200 MB
## Directory : /oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer
##   Job Started : Wed May  1 05:02:22 PM EDT 2024
###############################################################################

    Copy/Paste this in your local terminal to ssh tunnel with remote
    -----------------------------------------------------------------
    ssh -N -L 9512:172.20.217.9:9512 syu66@ssh.ccv.brown.edu
    -----------------------------------------------------------------
    Then open a browser on your local machine to the following address
    ------------------------------------------------------------------
    localhost:9512  (prefix w/ https:// if using password)
    ------------------------------------------------------------------
    
Wed May  1 17:02:22 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:61:00.0 Off |                  N/A |
| 30%   23C    P8              28W / 350W |     25MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     52857      G   /usr/libexec/Xorg                            17MiB |
+---------------------------------------------------------------------------------------+
  0%|          | 0/24 [00:00<?, ?it/s]100%|██████████| 24/24 [00:00<00:00, 729444.17it/s]
  0%|          | 0/24 [00:00<?, ?it/s]100%|██████████| 24/24 [00:00<00:00, 768422.11it/s]
Using cache found in /users/syu66/.cache/torch/hub/pytorch_vision_v0.10.0
EPOCH 1:
Batch 1/1: 0it [00:00, ?it/s]Batch 1/1: 1it [00:39, 39.67s/it]Batch 1/1: 1it [00:39, 39.67s/it]
batch 1 loss: 249056000.0
Average loss for epoch: 249056000.0
EPOCH 0, loss: 249056000.0
EPOCH 2:
Batch 1/1: 0it [00:00, ?it/s]Batch 1/1: 1it [00:39, 39.25s/it]Batch 1/1: 1it [00:39, 39.25s/it]
batch 1 loss: 10413340672.0
Average loss for epoch: 10413340672.0
EPOCH 1, loss: 10413340672.0
EPOCH 3:
Batch 1/1: 0it [00:00, ?it/s]Batch 1/1: 1it [00:38, 38.79s/it]Batch 1/1: 1it [00:38, 38.79s/it]
batch 1 loss: 8693241856.0
Average loss for epoch: 8693241856.0
EPOCH 2, loss: 8693241856.0
torch.Size([1, 3, 330, 256])
torch.Size([1, 3, 332, 256])
