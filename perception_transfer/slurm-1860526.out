## SLURM PROLOG ###############################################################
##    Job ID : 1860526
##  Job Name : batch.sh
##  Nodelist : gpu2114
##      CPUs : 1
##   Mem/CPU : 51200 MB
## Directory : /oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer
##   Job Started : Wed May  1 04:06:20 PM EDT 2024
###############################################################################

    Copy/Paste this in your local terminal to ssh tunnel with remote
    -----------------------------------------------------------------
    ssh -N -L 9774:172.20.217.14:9774 syu66@ssh.ccv.brown.edu
    -----------------------------------------------------------------
    Then open a browser on your local machine to the following address
    ------------------------------------------------------------------
    localhost:9774  (prefix w/ https:// if using password)
    ------------------------------------------------------------------
    
Wed May  1 16:06:20 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:81:00.0 Off |                  N/A |
| 30%   28C    P8              22W / 350W |     29MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     46208      G   /usr/libexec/Xorg                            21MiB |
+---------------------------------------------------------------------------------------+
  0%|          | 0/24 [00:00<?, ?it/s]100%|██████████| 24/24 [00:00<00:00, 811800.77it/s]
  0%|          | 0/24 [00:00<?, ?it/s]100%|██████████| 24/24 [00:00<00:00, 853078.78it/s]
Using cache found in /users/syu66/.cache/torch/hub/pytorch_vision_v0.10.0
EPOCH 1:
Batch 1/2: 0it [00:00, ?it/s]/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py:44: UserWarning: Using a target size (torch.Size([1, 256, 64, 64])) that is different to the input size (torch.Size([1, 256, 62, 62])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  L_content += mse_loss(F[l][1], target_F[l][1])
Batch 1/2: 0it [00:04, ?it/s]
Traceback (most recent call last):
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py", line 142, in <module>
    main()
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py", line 109, in main
    avg_loss = train_one_epoch()
               ^^^^^^^^^^^^^^^^^
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py", line 78, in train_one_epoch
    loss = loss_function(y_hats_normalized, y_originals_normalized)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py", line 44, in loss_function
    L_content += mse_loss(F[l][1], target_F[l][1])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/functional.py", line 3365, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/functional.py", line 76, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The size of tensor a (62) must match the size of tensor b (64) at non-singleton dimension 3
Traceback (most recent call last):
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/test.py", line 33, in <module>
    main()
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/test.py", line 12, in main
    model.load_state_dict(torch.load("model.pt"))
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 2189, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for ImageTransformer:
	Missing key(s) in state_dict: "down.6.weight", "down.6.bias", "down.7.weight", "down.7.bias", "down.7.running_mean", "down.7.running_var", "up.6.weight", "up.6.bias", "up.8.weight", "up.8.bias", "up.8.running_mean", "up.8.running_var". 
	size mismatch for down.0.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 3, 9, 9]).
	size mismatch for down.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.3.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).
	size mismatch for down.3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for down.4.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for down.4.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for down.4.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for down.4.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for up.3.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).
	size mismatch for up.3.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for up.5.weight: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for up.5.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for up.5.running_mean: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for up.5.running_var: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
