## SLURM PROLOG ###############################################################
##    Job ID : 1860477
##  Job Name : batch.sh
##  Nodelist : gpu2106
##      CPUs : 1
##   Mem/CPU : 51200 MB
## Directory : /oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer
##   Job Started : Wed May  1 03:53:42 PM EDT 2024
###############################################################################

    Copy/Paste this in your local terminal to ssh tunnel with remote
    -----------------------------------------------------------------
    ssh -N -L 9537:172.20.217.6:9537 syu66@ssh.ccv.brown.edu
    -----------------------------------------------------------------
    Then open a browser on your local machine to the following address
    ------------------------------------------------------------------
    localhost:9537  (prefix w/ https:// if using password)
    ------------------------------------------------------------------
    
Wed May  1 15:53:42 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:25:00.0 Off |                  N/A |
| 30%   28C    P8              26W / 350W |     13MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     54368      G   /usr/libexec/Xorg                             5MiB |
+---------------------------------------------------------------------------------------+
  0%|          | 0/24 [00:00<?, ?it/s]100%|██████████| 24/24 [00:00<00:00, 756866.89it/s]
  0%|          | 0/24 [00:00<?, ?it/s]100%|██████████| 24/24 [00:00<00:00, 666644.34it/s]
Using cache found in /users/syu66/.cache/torch/hub/pytorch_vision_v0.10.0
EPOCH 1:
Batch 1/2: 0it [00:00, ?it/s]Batch 1/2: 0it [00:03, ?it/s]
Traceback (most recent call last):
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py", line 142, in <module>
    main()
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py", line 109, in main
    avg_loss = train_one_epoch()
               ^^^^^^^^^^^^^^^^^
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/train.py", line 71, in train_one_epoch
    y_hats = model(y_originals)
             ^^^^^^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/image_transform_net.py", line 96, in forward
    x = self.up(x)
        ^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 952, in forward
    return F.conv_transpose2d(
           ^^^^^^^^^^^^^^^^^^^
RuntimeError: output padding must be smaller than either stride or dilation, but got output_padding_height: 1 output_padding_width: 1 stride_height: 1 stride_width: 1 dilation_height: 1 dilation_width: 1
Traceback (most recent call last):
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/test.py", line 33, in <module>
    main()
  File "/oscar/home/syu66/Documents/cs143-final-artist-dupes/perception_transfer/test.py", line 12, in main
    model.load_state_dict(torch.load("model.pt"))
  File "/users/syu66/.conda/envs/torchenv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 2189, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for ImageTransformer:
	Missing key(s) in state_dict: "down.6.weight", "down.6.bias", "down.7.weight", "down.7.bias", "down.7.running_mean", "down.7.running_var", "up.6.weight", "up.6.bias", "up.8.weight", "up.8.bias", "up.8.running_mean", "up.8.running_var". 
	size mismatch for down.0.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 3, 9, 9]).
	size mismatch for down.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for down.3.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).
	size mismatch for down.3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for down.4.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for down.4.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for down.4.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for down.4.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for up.3.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 3]).
	size mismatch for up.3.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for up.5.weight: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for up.5.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for up.5.running_mean: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for up.5.running_var: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([32]).
